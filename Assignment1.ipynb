{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dq0LqCJMfYe8"
   },
   "source": [
    "# Assignment 1 Workbook\n",
    "## Nguyen Vu\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVcqbt4DfYe_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmxLySb20jtX"
   },
   "outputs": [],
   "source": [
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q http://mirror.cc.columbia.edu/pub/software/apache/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-3.0.0-preview2-bin-hadoop2.7.tgz\n",
    "# !pip install -q findspark\n",
    "# !rm -rf spark-3.0.0-preview2-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nor9olN20p0M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-preview2-bin-hadoop2.7\"\n",
    "\n",
    "#import findspark\n",
    "# findspark.init(\"spark-3.0.0-preview2-bin-hadoop2.7\")# SPARK_HOME\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "SY060QsjT8Wr",
    "outputId": "a85039e0-5341-4ff6-dddf-75a1953f063f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 104\r\n",
      "drwxr-xr-x  11 nguyendvu  staff   352B Jul 16 19:21 \u001b[34m.\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x@ 82 nguyendvu  staff   2.6K Jul 16 14:29 \u001b[34m..\u001b[m\u001b[m/\r\n",
      "-rw-r--r--@  1 nguyendvu  staff    10K Jul 16 14:35 .DS_Store\r\n",
      "drwxr-xr-x   4 nguyendvu  staff   128B Jul 15 18:59 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m/\r\n",
      "-rw-r--r--@  1 nguyendvu  staff    26K Jul 16 19:21 Assignment1.ipynb\r\n",
      "-rw-r--r--   1 nguyendvu  staff   8.7K Jul 15 19:39 Assignment1_OLD.ipynb\r\n",
      "drwxr-xr-x   5 nguyendvu  staff   160B Jul 11 12:39 \u001b[34mAssignment1_dt\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   9 nguyendvu  staff   288B Jul 16 14:34 \u001b[34mBigDataNBs\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   6 nguyendvu  staff   192B Jul 15 21:34 \u001b[34mtop10Drivers\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   6 nguyendvu  staff   192B Jul 15 21:34 \u001b[34mtop10Taxi\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x   6 nguyendvu  staff   192B Jul 15 21:37 \u001b[34mtop10WorkHours\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "OYvYeA5RUImn",
    "outputId": "92c809b5-3a7c-4192-a346-f760c9b4cfd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 104\r\n",
      "drwxr-xr-x  11 nguyendvu  staff    352 Jul 16 19:21 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@ 82 nguyendvu  staff   2624 Jul 16 14:29 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 nguyendvu  staff  10244 Jul 16 14:35 .DS_Store\r\n",
      "drwxr-xr-x   4 nguyendvu  staff    128 Jul 15 18:59 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 nguyendvu  staff  26566 Jul 16 19:21 Assignment1.ipynb\r\n",
      "-rw-r--r--   1 nguyendvu  staff   8916 Jul 15 19:39 Assignment1_OLD.ipynb\r\n",
      "drwxr-xr-x   5 nguyendvu  staff    160 Jul 11 12:39 \u001b[34mAssignment1_dt\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   9 nguyendvu  staff    288 Jul 16 14:34 \u001b[34mBigDataNBs\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   6 nguyendvu  staff    192 Jul 15 21:34 \u001b[34mtop10Drivers\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   6 nguyendvu  staff    192 Jul 15 21:34 \u001b[34mtop10Taxi\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   6 nguyendvu  staff    192 Jul 15 21:37 \u001b[34mtop10WorkHours\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ik5qs0pnKC60",
    "outputId": "fad6c105-49ed-4486-d2bc-eb67a185fc63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: install [-bCcpSsv] [-B suffix] [-f flags] [-g group] [-m mode]\n",
      "               [-o owner] file1 file2\n",
      "       install [-bCcpSsv] [-B suffix] [-f flags] [-g group] [-m mode]\n",
      "               [-o owner] file1 ... fileN directory\n",
      "       install -d [-v] [-g group] [-m mode] [-o owner] directory ...\n",
      "/bin/sh: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "!install conda install -c anaconda wget\n",
    "!wget https://s3.amazonaws.com/metcs777/taxi-data-sorted-small.csv.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "acu6srVpfYfH",
    "outputId": "15a350d5-6950-4e52-9ade-c0c68c8b66b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "#check if spark are running\n",
    "\n",
    "print(sc.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gT2D6DuJfYfM"
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"Assignment1_dt/taxi-data-sorted-small.csv.bz2\")\n",
    "taxilines = lines.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "w56VdzMEfYfQ",
    "outputId": "11d48f0c-977a-44db-8acd-e72e2fe3bde3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['07290D3599E7A0D62097A346EFCC1FB5', 'E7750A37CAB07D0DFF0AF7E3573AC141', '2013-01-01 00:00:00', '2013-01-01 00:02:00', '120', '0.44', '-73.956528', '40.716976', '-73.962440', '40.715008', 'CSH', '3.50', '0.50', '0.50', '0.00', '0.00', '4.50'], ['22D70BF00EEB0ADC83BA8177BB861991', '3FF2709163DE7036FCAA4E5A3324E4BF', '2013-01-01 00:02:00', '2013-01-01 00:02:00', '0', '0.00', '0.000000', '0.000000', '0.000000', '0.000000', 'CSH', '27.00', '0.00', '0.50', '0.00', '0.00', '27.50']]\n"
     ]
    }
   ],
   "source": [
    "#print first row of the data to make sure it is read in correctly\n",
    "print(taxilines.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWUNSZLQfYfW"
   },
   "source": [
    "Use pycode from assignment 1 document to clean up the data loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56bFmBB0fYfX"
   },
   "outputs": [],
   "source": [
    "#clean up \n",
    "#handling wrong data lines\n",
    "def isfloat(val):\n",
    "    try: \n",
    "        float(val)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "#use isFloat to remove lines if they dont have 16 values and a float value !=0 for col 6 and col 12\n",
    "def correctRows(p):\n",
    "    if(len(p)==17):\n",
    "        if(isfloat(p[5]) and isfloat(p[11])):\n",
    "            if(float(p[5])!=0 and float(p[11])!=0):\n",
    "                return p\n",
    "            \n",
    "#go thru each element per row and keep only the correctRows\n",
    "cleanTaxiDT = taxilines.filter(correctRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ao7ZkqSTfYfi"
   },
   "source": [
    "### Part1: Top-10 Active Taxis\n",
    "Many different taxis have had multiple drivers. Write and execute a Spark Python program that computes\n",
    "the top ten taxis that have had the largest number of drivers. Your output should be a set of (medallion,\n",
    "number of drivers) pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvBUCe_ufYfj"
   },
   "outputs": [],
   "source": [
    "#set up each row with an 1 index\n",
    "rdd_1 = cleanTaxiDT.map(lambda x: ((x[0], x[1]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wDyrz-5ffYfm",
    "outputId": "bcc63e08-380b-4c29-ff71-ee8e7edcbcb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('07290D3599E7A0D62097A346EFCC1FB5', 'E7750A37CAB07D0DFF0AF7E3573AC141'), 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVq_pvVlfYfp"
   },
   "outputs": [],
   "source": [
    "#reduce, aggrgate by the combination of taxi and taxi drivers into a list\n",
    "rdd_1_reduce = rdd_1.reduceByKey(lambda x, y: x+y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYRaU5MrfYft"
   },
   "outputs": [],
   "source": [
    "# reduce in RDD to count taxi and most frequently used taxi\n",
    "by_medalionRDD2 = rdd_1_reduce.map(lambda x: (x[0][0],1)).reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZjVMIVTfYfv"
   },
   "outputs": [],
   "source": [
    "#return the top 10 most used taxi by the count\n",
    "top10taxi = sc.parallelize(by_medalionRDD2.top(10, lambda x: x[1]))\n",
    "\n",
    "top10taxi.coalesce(1).saveAsTextFile(\"top10Taxi/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5_i58u3fYf4"
   },
   "source": [
    "### Part2: Top-10 Best Drivers\n",
    "We would like to figure out who the top 10 best drivers are in terms of their average earned money per minute spent carrying a customer. The total amount field is the total money earned on a trip. In the end, we\n",
    "are interested in computing a set of (driver, money per minute) pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F8eA3mOHCF0O"
   },
   "source": [
    "Create a second clean RDD to remove any rows that contain no value for the minute column and save to cleanTaxiDT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_ZHanAFojAq"
   },
   "outputs": [],
   "source": [
    "def correctRows2(p):\n",
    "  if(float(p[4]) !=0):\n",
    "    return p\n",
    "cleanTaxiDT2 = cleanTaxiDT.filter(correctRows2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xiTxqgSQBmDd",
    "outputId": "eaf0cbac-8820-4e0a-e647-4ff2db55cc54"
   },
   "outputs": [],
   "source": [
    "# check to see if the cleaned up data contail any zero value for column 5\n",
    "cleanTaxiDT2.filter(lambda x: float(x[4])==0 ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcDeqY6zfYf5"
   },
   "outputs": [],
   "source": [
    "#get a driver rdd and map a function to get the money per minute value\n",
    "by_drvr = cleanTaxiDT2.map(lambda x: (x[1], (float(x[11])/(float(x[4])/60), 1.0)))\n",
    "#aggregate by key=driverID and tke an average using the aggregate byByKey\n",
    "aggfun = lambda x, y: (x[0]+y[0], x[1]+y[1])\n",
    "rateRDD = by_drvr.aggregateByKey((0.0,0.0), aggfun, aggfun)\n",
    "\n",
    "avg_rateRDD = rateRDD.map(lambda x: (x[0], x[1][0]/x[1][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "QRNuqmzwfYgD",
    "outputId": "a44dfd49-598b-4d83-d600-eb748f45d843"
   },
   "outputs": [],
   "source": [
    "# Get top 10 drivers\n",
    "top10drivers = sc.parallelize(avg_rateRDD.top(10, lambda x: x[1]))\n",
    "top10drivers.coalesce(1).saveAsTextFile(\"top10Drivers/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZ6isU0PJN6L"
   },
   "source": [
    "### Part3: Best Day to Work\n",
    "We would like to know which hour of the day is the best time for drivers that has the highest profit per miles. Consider the surcharge amount in dollar for each taxi ride (without tip amount) and the distance in miles, and sum up the rides for each hour of the day (24 hours) â€“ consider the pickup time for your calculation. The profit ratio is the ration surcharge in dollar divided by the travel distance in miles for each specific time\n",
    "of the day. \n",
    "\n",
    "Profit Ratio = (Surcharge Amount in US Dollar) / (Travel Distance in miles)\n",
    "We are interested to know the time of the day that has the highest profit ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yW0RJ81ZfYgV"
   },
   "outputs": [],
   "source": [
    "#col index: surcharge=12, Distance=5, pickup datetime=2\n",
    "\n",
    "# get the day out of the datetime column\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_8J-7X5N_DB"
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a method to extract hour\n",
    "def getHour(x):\n",
    "  dtObj = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "  return dtObj.strftime('%H')\n",
    "\n",
    "#create aRDD with the relevant columns: pick up date, surcharge, distance\n",
    "pt3RDD = cleanTaxiDT.map(lambda x: (getHour(x[2]), (float(x[12]), float(x[5]))))\n",
    "#RDD to contain sum of all surcharge, all distance for each date as key\n",
    "byHourRDD = pt3RDD.reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "#RDD to produce date and profit ratio by day\n",
    "bestDayRDD = byHourRDD.map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('04', 0.11624931403920391)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestDayRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "rdadRG-KORSd",
    "outputId": "fac61e66-b459-4b34-858a-56fc296b6269"
   },
   "outputs": [],
   "source": [
    "bestWrkHr = sc.parallelize(bestDayRDD.top(10, lambda x: x[1]))\n",
    "\n",
    "#bestWrkHr.coalesce(1).saveAsTextFile(\"top10WorkHours/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trlcSiumWOVT"
   },
   "source": [
    "### Part4: Bonus \n",
    "How many percent of taxi customers pay with cash and how many percent using electronic cards?\n",
    "Analyze these payment methods for different time of the day and provide a list of percents for each\n",
    "day time? \n",
    "\n",
    "As a result provide two numbers for total percentages and a list like (hour of day, percent paid card) We would like to measure the efficiency of taxis drivers by finding out their average earned money per mile. (Consider the total amount which includes tips, as their earned money) Implement a Spark job\n",
    "that can find out the top-10 efficient taxi divers.\n",
    "\n",
    "\u000fWhat are mean, median, first and third quantiles of tip amount? How do find the median?\n",
    "\u000fUsing the IQR outlier detection method find out the top-10 outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-FV5H0TWpLj"
   },
   "outputs": [],
   "source": [
    "# cash versus credit\n",
    "# columns: pickup date = 2, payment type = 10, trip distance = 5, fare amount = 11, surcharge = 12, tax = 13, tip = 14\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "rdd_transf = cleanTaxiDT.map(lambda x: [x[num] for num in [0, 1, 2, 10, 5, 11, 12, 13, 14]])\n",
    "\n",
    "colnames = ['TaxiID','DriverID','DateTime', 'PaymentType', 'Distance', 'Fare', 'Surcharge', 'Tax', 'Tip']\n",
    "\n",
    "\n",
    "sFields = [StructField(field, StringType(), True) for field in colnames]\n",
    "\n",
    "schema = StructType(sFields)\n",
    "\n",
    "df_bonus = sqlContext.createDataFrame(rdd_transf, schema)\n",
    "\n",
    "rename_col = colnames[4:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected DF to cask certain columns but this will change the DF\n",
    "correctedDF = df_bonus.select(*(F.col(c).cast('float') for c in rename_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename all columns and maintain the other columns.\n",
    "for colname in rename_col:\n",
    "    df_bonus = df_bonus.withColumn(colname, F.col(colname).cast('float'))\n",
    "    \n",
    "#add column for date and hour\n",
    "# create a method to extract hour\n",
    "def getHour(x):\n",
    "  dtObj = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "  return dtObj.strftime('%H')\n",
    "\n",
    "#establish UDF\n",
    "udfGetHour = F.udf(getHour, StringType())\n",
    "\n",
    "df_bonus = df_bonus.withColumn('Hour', udfGetHour(df_bonus.DateTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bonus.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-----------+--------+----+---------+---+---+----+\n",
      "|              TaxiID|            DriverID|           DateTime|PaymentType|Distance|Fare|Surcharge|Tax|Tip|Hour|\n",
      "+--------------------+--------------------+-------------------+-----------+--------+----+---------+---+---+----+\n",
      "|07290D3599E7A0D62...|E7750A37CAB07D0DF...|2013-01-01 00:00:00|        CSH|    0.44| 3.5|      0.5|0.5|0.0|  00|\n",
      "+--------------------+--------------------+-------------------+-----------+--------+----+---------+---+---+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bonus.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the count split up by payment type as a total of all payment \n",
    "paymentType = df_bonus.groupBy('PaymentType').count()\n",
    "\n",
    "total = df_bonus.count()\n",
    "\n",
    "#add % by total column to calculate count by total rows\n",
    "paymentTypeOut = paymentType.withColumn(\"%_of_total\", (F.col('count')/total)*100)\n",
    "#total %paid by different methods\n",
    "paymentTypeOut.rdd.map(list).coalesce(1).saveAsTextFile(\"percentCardVsCash/\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-----------+--------+----+---------+---+---+----+-----------------+\n",
      "|              TaxiID|            DriverID|           DateTime|PaymentType|Distance|Fare|Surcharge|Tax|Tip|Hour|    dollarPerMile|\n",
      "+--------------------+--------------------+-------------------+-----------+--------+----+---------+---+---+----+-----------------+\n",
      "|07290D3599E7A0D62...|E7750A37CAB07D0DF...|2013-01-01 00:00:00|        CSH|    0.44| 3.5|      0.5|0.5|0.0|  00|10.22727278269027|\n",
      "+--------------------+--------------------+-------------------+-----------+--------+----+---------+---+---+----+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#analyze average earn per mile\n",
    "\n",
    "df_bonus = df_bonus.withColumn('dollarPerMile', \n",
    "                               ((F.col('Fare')+F.col('Surcharge')+F.col('Tax')+F.col('Tip'))/F.col('Distance')))\n",
    "\n",
    "df_bonus.show(1)\n",
    "\n",
    "bydriverdf = df_bonus.groupBy('DriverID').mean('dollarPerMile')\n",
    "\n",
    "top10DriverByMile = bydriverdf.orderBy(\"avg(dollarPerMile)\", ascending=0).head(10)\n",
    "\n",
    "top10DriverByMileRDD = sc.parallelize(top10DriverByMile)\n",
    "\n",
    "top10DriverByMileRDD.coalesce(1).saveAsTextFile(\"top10DriverByMile/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the summary of statistics for Tips, and quantiles of tips amount\n",
    "df_bonus.describe('Tip').rdd.map(list).coalesce(1).saveAsTextFile(\"TipsSummaryStats/\")\n",
    "\n",
    "tipsQuantiles = df_bonus.approxQuantile('Tip', [0.25, 0.5, 0.75], 0.25)\n",
    "\n",
    "sc.parallelize(tipsQuantiles).coalesce(1).saveAsTextFile(\"TipsQuantiles/\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ao7ZkqSTfYfi"
   ],
   "name": "Assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
